{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`true_m` and `true_b` are the true parameters of the function for the training data.\n",
    "\n",
    "Prepare the data, randomize all input x, then calculate the true y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5704]) tensor([-1.9661])\n"
     ]
    }
   ],
   "source": [
    "true_m = torch.randn(1)\n",
    "true_b = torch.randn(1)\n",
    "x = torch.randn((10000, 1))\n",
    "y = x * true_m + true_b\n",
    "\n",
    "print(true_m, true_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two trainable parameters, `m` and `b` for our linear regressor. Don't forget to use `requires_grad=True` to enable backprop.\n",
    "\n",
    "Also create the optimizer to train the parameters (in this case, we will use classic SGD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.randn(1, requires_grad=True)\n",
    "b = torch.randn(1, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-5\n",
    "optimizer = torch.optim.SGD((m, b), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training procedure:\n",
    "\n",
    "1. Calculate the predicted y (`y_hat`) using our parameters.\n",
    "2. Calculate the loss\n",
    "3. Reset the gradient to zero before doing backprop, then do the gradient descent by running `optimizer.step()` to update our parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 51008.28515625\n",
      "1 32793.4140625\n",
      "2 21083.337890625\n",
      "3 13555.0146484375\n",
      "4 8714.99609375\n",
      "5 5603.2841796875\n",
      "6 3602.67919921875\n",
      "7 2316.408447265625\n",
      "8 1489.4039306640625\n",
      "9 957.6722412109375\n",
      "10 615.78466796875\n",
      "11 395.9565734863281\n",
      "12 254.60874938964844\n",
      "13 163.72166442871094\n",
      "14 105.28018188476562\n",
      "15 67.700927734375\n",
      "16 43.53604507446289\n",
      "17 27.99686622619629\n",
      "18 18.004390716552734\n",
      "19 11.578564643859863\n",
      "20 7.44623327255249\n",
      "21 4.788790702819824\n",
      "22 3.0798134803771973\n",
      "23 1.9807467460632324\n",
      "24 1.273918867111206\n",
      "25 0.8193403482437134\n",
      "26 0.5269775390625\n",
      "27 0.3389357030391693\n",
      "28 0.21800442039966583\n",
      "29 0.14022211730480194\n",
      "30 0.09019436687231064\n",
      "31 0.0580126978456974\n",
      "32 0.037313614040613174\n",
      "33 0.024002831429243088\n",
      "34 0.015440566465258598\n",
      "35 0.009931180626153946\n",
      "36 0.0063893175683915615\n",
      "37 0.004109669476747513\n",
      "38 0.0026432627346366644\n",
      "39 0.0017006591660901904\n",
      "40 0.0010938042541965842\n",
      "41 0.000703425204847008\n",
      "42 0.00045233857235871255\n",
      "43 0.0002911812625825405\n",
      "44 0.00018748464935924858\n",
      "45 0.00012062038877047598\n",
      "46 7.766439375700429e-05\n",
      "47 4.994702248950489e-05\n",
      "48 3.208390626241453e-05\n",
      "49 2.0624174794647843e-05\n",
      "50 1.3312304872670211e-05\n",
      "51 8.551185601390898e-06\n",
      "52 5.496280664374353e-06\n",
      "53 3.5325517728779232e-06\n",
      "54 2.2720305423717946e-06\n",
      "55 1.457301664231636e-06\n",
      "56 9.342589919469901e-07\n",
      "57 5.962701266071235e-07\n",
      "58 3.8470935237455706e-07\n",
      "59 2.4808775833662366e-07\n",
      "60 1.569895289321721e-07\n",
      "61 1.0249375037574282e-07\n",
      "62 6.6277237920076e-08\n",
      "63 4.450423318758112e-08\n",
      "64 2.8447402655729093e-08\n",
      "65 1.8293107473255077e-08\n",
      "66 1.1182102355178358e-08\n",
      "67 7.970314186422911e-09\n",
      "68 5.307892791961422e-09\n",
      "69 3.5730032266201306e-09\n",
      "70 2.192827253111318e-09\n",
      "71 1.1743814809506148e-09\n",
      "72 9.456648797367961e-10\n",
      "73 7.708571558850963e-10\n",
      "74 7.708571558850963e-10\n",
      "75 7.708571558850963e-10\n",
      "76 7.708571558850963e-10\n",
      "77 7.708571558850963e-10\n",
      "78 7.708571558850963e-10\n",
      "79 7.708571558850963e-10\n",
      "80 7.708571558850963e-10\n",
      "81 7.708571558850963e-10\n",
      "82 7.708571558850963e-10\n",
      "83 7.708571558850963e-10\n",
      "84 7.708571558850963e-10\n",
      "85 7.708571558850963e-10\n",
      "86 7.708571558850963e-10\n",
      "87 7.708571558850963e-10\n",
      "88 7.708571558850963e-10\n",
      "89 7.708571558850963e-10\n",
      "90 7.708571558850963e-10\n",
      "91 7.708571558850963e-10\n",
      "92 7.708571558850963e-10\n",
      "93 7.708571558850963e-10\n",
      "94 7.708571558850963e-10\n",
      "95 7.708571558850963e-10\n",
      "96 7.708571558850963e-10\n",
      "97 7.708571558850963e-10\n",
      "98 7.708571558850963e-10\n",
      "99 7.708571558850963e-10\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    y_hat = x * m + b\n",
    "    \n",
    "    loss = (y - y_hat).pow(2).sum()\n",
    "    print(i, loss.item())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True m = 0.5704447031021118, True b = -1.966130018234253\n",
      "Trained m = 0.5704445838928223, Trained b = -1.9661297798156738\n"
     ]
    }
   ],
   "source": [
    "print(\"True m = {}, True b = {}\".format(true_m.item(), true_b.item()))\n",
    "print(\"Trained m = {}, Trained b = {}\".format(m.item(), b.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
